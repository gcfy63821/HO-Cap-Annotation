Runnning hand detection
[20250715;16:08:55] [HandJointsDetector:run] [INF] ====================================================================================================
[20250715;16:08:55] [HandJointsDetector:run] [INF] Starting Hand Landmarks Detection for 20250704_172530
[20250715;16:08:55] [HandJointsDetector:run] [INF] ====================================================================================================
[20250715;16:08:55] [HandJointsDetector:detect_mp_handmarks] [INF] >>>>>>>>>> Running MediaPipe Hand Detection <<<<<<<<<<
[DEBUG] Object group layer not loaded.
  0%|                                                                         | 0/8 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1752566937.900880 2793947 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5
I0000 00:00:1752566937.978632 2794119 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 565.57.01), renderer: NVIDIA GeForce RTX 2080 Ti/PCIe/SSE2
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1752566939.256033 2793948 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5
I0000 00:00:1752566939.337384 2794300 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 565.57.01), renderer: NVIDIA GeForce RTX 2080 Ti/PCIe/SSE2
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1752566940.548759 2793949 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5
I0000 00:00:1752566940.636050 2794319 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 565.57.01), renderer: NVIDIA GeForce RTX 2080 Ti/PCIe/SSE2
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1752566941.704185 2793950 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5
I0000 00:00:1752566941.789098 2794322 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 565.57.01), renderer: NVIDIA GeForce RTX 2080 Ti/PCIe/SSE2
I0000 00:00:1752566942.878998 2793947 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5
I0000 00:00:1752566942.940919 2794324 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 565.57.01), renderer: NVIDIA GeForce RTX 2080 Ti/PCIe/SSE2
I0000 00:00:1752566944.360237 2793948 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5
I0000 00:00:1752566944.415958 2794326 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 565.57.01), renderer: NVIDIA GeForce RTX 2080 Ti/PCIe/SSE2
I0000 00:00:1752566945.946130 2793949 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5
I0000 00:00:1752566946.001336 2794328 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 565.57.01), renderer: NVIDIA GeForce RTX 2080 Ti/PCIe/SSE2
I0000 00:00:1752566947.709372 2793950 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5
I0000 00:00:1752566947.764748 2794330 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 565.57.01), renderer: NVIDIA GeForce RTX 2080 Ti/PCIe/SSE2
self.config: {'max_num_hands': 0, 'min_hand_detection_confidence': 0.1, 'min_tracking_confidence': 0.5, 'min_hand_presence_confidence': 0.5, 'running_mode': 'video', 'frame_rate': 30, 'model_asset_path': 'config/checkpoints/mediapipe/hand_landmarker.task', 'device': 'cuda'}
DEBUG: 0
self.config: {'max_num_hands': 0, 'min_hand_detection_confidence': 0.1, 'min_tracking_confidence': 0.5, 'min_hand_presence_confidence': 0.5, 'running_mode': 'video', 'frame_rate': 30, 'model_asset_path': 'config/checkpoints/mediapipe/hand_landmarker.task', 'device': 'cuda'}
DEBUG: 0
self.config: {'max_num_hands': 0, 'min_hand_detection_confidence': 0.1, 'min_tracking_confidence': 0.5, 'min_hand_presence_confidence': 0.5, 'running_mode': 'video', 'frame_rate': 30, 'model_asset_path': 'config/checkpoints/mediapipe/hand_landmarker.task', 'device': 'cuda'}
DEBUG: 0
self.config: {'max_num_hands': 0, 'min_hand_detection_confidence': 0.1, 'min_tracking_confidence': 0.5, 'min_hand_presence_confidence': 0.5, 'running_mode': 'video', 'frame_rate': 30, 'model_asset_path': 'config/checkpoints/mediapipe/hand_landmarker.task', 'device': 'cuda'}
DEBUG: 0
self.config: {'max_num_hands': 0, 'min_hand_detection_confidence': 0.1, 'min_tracking_confidence': 0.5, 'min_hand_presence_confidence': 0.5, 'running_mode': 'video', 'frame_rate': 30, 'model_asset_path': 'config/checkpoints/mediapipe/hand_landmarker.task', 'device': 'cuda'}
DEBUG: 0
self.config: {'max_num_hands': 0, 'min_hand_detection_confidence': 0.1, 'min_tracking_confidence': 0.5, 'min_hand_presence_confidence': 0.5, 'running_mode': 'video', 'frame_rate': 30, 'model_asset_path': 'config/checkpoints/mediapipe/hand_landmarker.task', 'device': 'cuda'}
DEBUG: 0
self.config: {'max_num_hands': 0, 'min_hand_detection_confidence': 0.1, 'min_tracking_confidence': 0.5, 'min_hand_presence_confidence': 0.5, 'running_mode': 'video', 'frame_rate': 30, 'model_asset_path': 'config/checkpoints/mediapipe/hand_landmarker.task', 'device': 'cuda'}
DEBUG: 0
self.config: {'max_num_hands': 0, 'min_hand_detection_confidence': 0.1, 'min_tracking_confidence': 0.5, 'min_hand_presence_confidence': 0.5, 'running_mode': 'video', 'frame_rate': 30, 'model_asset_path': 'config/checkpoints/mediapipe/hand_landmarker.task', 'device': 'cuda'}
DEBUG: 0
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/wys/anaconda3/envs/hocap-annotation/lib/python3.10/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/tools/02_mp_hand_detection.py", line 46, in run_mp_hand_detector
    detector = MPHandDetector(mp_config)
  File "/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/hocap_annotation/wrappers/mediapipe.py", line 14, in __init__
    self._detector = self._init_mp_hand_detector()
  File "/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/hocap_annotation/wrappers/mediapipe.py", line 40, in _init_mp_hand_detector
    return mp.tasks.vision.HandLandmarker.create_from_options(mp_options)
  File "/home/wys/anaconda3/envs/hocap-annotation/lib/python3.10/site-packages/mediapipe/tasks/python/vision/hand_landmarker.py", line 364, in create_from_options
    return cls(
  File "/home/wys/anaconda3/envs/hocap-annotation/lib/python3.10/site-packages/mediapipe/tasks/python/vision/core/base_vision_task_api.py", line 70, in __init__
    self._runner = _TaskRunner.create(graph_config, packet_callback)
RuntimeError: ValidatedGraphConfig Initialization failed.
ClipNormalizedRectVectorSizeCalculator: max_vec_size should be greater than or equal to 1.
ClipNormalizedRectVectorSizeCalculator: max_vec_size should be greater than or equal to 1.
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/tools/02_mp_hand_detection.py", line 227, in <module>
    detector.run()
  File "/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/tools/02_mp_hand_detection.py", line 210, in run
    self.detect_mp_handmarks()
  File "/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/tools/02_mp_hand_detection.py", line 122, in detect_mp_handmarks
    mp_handmarks[serial] = future.result()
  File "/home/wys/anaconda3/envs/hocap-annotation/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/wys/anaconda3/envs/hocap-annotation/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
RuntimeError: ValidatedGraphConfig Initialization failed.
ClipNormalizedRectVectorSizeCalculator: max_vec_size should be greater than or equal to 1.
ClipNormalizedRectVectorSizeCalculator: max_vec_size should be greater than or equal to 1.
  0%|                                                                         | 0/8 [00:12<?, ?it/s]
Running hand 3d generation
Traceback (most recent call last):
  File "/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/tools/03_mp_3d_joints_generation.py", line 517, in <module>
    estimator = HandJointsEstimator(args.sequence_folder, args.debug)
  File "/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/tools/03_mp_3d_joints_generation.py", line 283, in __init__
    self._logger = get_logger(
  File "/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/hocap_annotation/utils/misc.py", line 30, in get_logger
    fh = logging.FileHandler(log_file)
  File "/home/wys/anaconda3/envs/hocap-annotation/lib/python3.10/logging/__init__.py", line 1169, in __init__
    StreamHandler.__init__(self, self._open())
  File "/home/wys/anaconda3/envs/hocap-annotation/lib/python3.10/logging/__init__.py", line 1201, in _open
    return open_func(self.baseFilename, self.mode,
FileNotFoundError: [Errno 2] No such file or directory: '/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/my_dataset/blue_scooper_1/20250704_172530/processed/hand_detection/mp_3d_joints_estimation.log'
Running fd_pose_solver with object_idx=1...
/home/wys/anaconda3/envs/hocap-annotation/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/third_party/FoundationPose/learning/training/predict_score.py:151: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(ckpt_dir)
/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/third_party/FoundationPose/learning/training/predict_pose_refine.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(ckpt_dir)
/home/wys/anaconda3/envs/hocap-annotation/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Warp 1.3.3 initialized:
   CUDA Toolkit 12.5, Driver 12.7
   Devices:
     "cpu"      : "x86_64"
     "cuda:0"   : "NVIDIA GeForce RTX 2080 Ti" (11 GiB, sm_75, mempool enabled)
   Kernel cache:
     /home/wys/.cache/warp/1.3.3
[DEBUG] : Mesh vertices: 129374, faces: 182698
Traceback (most recent call last):
  File "/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/tools/04-1-1_fd_pose_solver_prep.py", line 1038, in <module>
    run_pose_estimation(
  File "/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/tools/04-1-1_fd_pose_solver_prep.py", line 746, in run_pose_estimation
    estimator = FoundationPose(
  File "/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/hocap_annotation/wrappers/foundationpose.py", line 65, in __init__
    self.reset_object(
  File "/home/wys/learning-compliant/crq_ws/HO-Cap-Annotation/hocap_annotation/wrappers/foundationpose.py", line 105, in reset_object
    self.mesh.export(self.mesh_path)
  File "/home/wys/anaconda3/envs/hocap-annotation/lib/python3.10/site-packages/trimesh/base.py", line 2834, in export
    return export_mesh(mesh=self, file_obj=file_obj, file_type=file_type, **kwargs)
  File "/home/wys/anaconda3/envs/hocap-annotation/lib/python3.10/site-packages/trimesh/exchange/export.py", line 85, in export_mesh
    export = _mesh_exporters[file_type](mesh, **kwargs)
  File "/home/wys/anaconda3/envs/hocap-annotation/lib/python3.10/site-packages/trimesh/exchange/obj.py", line 941, in export_obj
    + util.array_to_string(
  File "/home/wys/anaconda3/envs/hocap-annotation/lib/python3.10/site-packages/trimesh/util.py", line 1069, in array_to_string
    formatted = format_str.format(*shaped)[:-end_junk]
KeyboardInterrupt
